# self-evolving-moe-router
Implements a neuro-evolution loop (mutate→score→select) that discovers sparse routing topologies for Mixture of Experts models. Seeded by evolutionary attention studies, this framework ships with slimmable expert checkpoints for adaptive deployment.
